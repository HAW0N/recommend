{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Elasticsearch 호스트 및 포트 설정\n",
    "host = '218.50.209.93'\n",
    "port = 20395\n",
    "scheme = 'http'\n",
    "es = Elasticsearch([{'host': host, 'port': port, 'scheme': scheme}])\n",
    "\n",
    "# 인덱스, 변수 이름 설정\n",
    "index_name = 'index'\n",
    "userid = ''  # userid를 받아야하는 경우 여기에 설정\n",
    "uid = ''  # uid를 받아야하는 경우 여기에 설정\n",
    "\n",
    "# uid 또는 userid에 따라 필드를 선택\n",
    "if uid:\n",
    "    field_name = \"uid.keyword\"\n",
    "else:\n",
    "    field_name = \"userId.keyword\"\n",
    "\n",
    "# 집계 쿼리 생성\n",
    "aggs_query = {\n",
    "    \"aggs\": {\n",
    "        \"2\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"requestUrl.keyword\",\n",
    "                \"order\": {\n",
    "                    \"_count\": \"desc\"\n",
    "                },\n",
    "                \"size\": 5\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"3\": {\n",
    "                    \"avg\": {\n",
    "                        \"field\": \"pageStayTime\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"size\": 0,\n",
    "    \"script_fields\": {},\n",
    "    \"stored_fields\": [\"*\"],\n",
    "    \"runtime_mappings\": {},\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"match_phrase\": {\n",
    "                        field_name: uid or userid\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"match_phrase\": {\n",
    "                        \"contentType.keyword\": \"bbs_policy_info\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"requestTime\": {\n",
    "                            \"format\": \"strict_date_optional_time\",\n",
    "                            \"gte\": \"2023-08-01T00:00:00.000Z\",\n",
    "                            \"lte\": \"2023-09-21T23:59:59.999Z\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"should\": [],\n",
    "            \"must_not\": []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Elasticsearch에 집계 쿼리를 실행하고 결과를 받기\n",
    "response = es.search(index=index_name, body=aggs_query)\n",
    "# 결과 처리\n",
    "aggregations = response.get('aggregations', {})\n",
    "# URL, count, pageStaytime을 저장할 배열\n",
    "url_data = []\n",
    "selected_url_list = []\n",
    "# Elasticsearch 집계 결과를 파싱하여 배열에 데이터 추가\n",
    "buckets = aggregations.get(\"2\", {}).get(\"buckets\", [])\n",
    "for bucket in buckets:\n",
    "    url = bucket.get(\"key\", \"\")\n",
    "    count = bucket.get(\"doc_count\", 0)\n",
    "    page_stay_time = bucket.get(\"3\", {}).get(\"value\", 0)  # 페이지 체류 시간\n",
    "    selected_url_list.append(url)\n",
    "    # URL, count, pageStaytime을 딕셔너리로 묶어 배열에 추가\n",
    "    url_data.append({\n",
    "        \"URL\": url,\n",
    "        \"Count\": count,\n",
    "        \"PageStayTime\": page_stay_time\n",
    "    })\n",
    "\n",
    "# 클릭 수와 체류 시간 데이터\n",
    "clicks = [data['Count'] for data in url_data]\n",
    "dwell_times = [data['PageStayTime'] for data in url_data]\n",
    "\n",
    "# 클릭 수와 체류 시간의 합을 계산\n",
    "total_clicks = sum(clicks)\n",
    "total_dwell_time = sum(dwell_times)\n",
    "\n",
    "# 클릭 수와 체류 시간의 상대적 비율 계산\n",
    "relative_clicks = [click / total_clicks for click in clicks]\n",
    "relative_dwell_times = [dwell_time / total_dwell_time for dwell_time in dwell_times]\n",
    "\n",
    "# 상대적 비율을 종합 점수로 계산 (예: 클릭 수와 체류 시간을 6:4 비율로 고려)\n",
    "weighted_scores = [(0.6 * relative_clicks[i]) + (0.4 * relative_dwell_times[i]) for i in range(len(clicks))]\n",
    "\n",
    "# 점수를 기준으로 데이터를 정렬하여 순위 지정\n",
    "ranked_indices = sorted(range(len(weighted_scores)), key=lambda i: weighted_scores[i], reverse=True)\n",
    "\n",
    "\n",
    "def send_to_engine_keyword(title, content):\n",
    "    D_ENGINE_URL = \"url\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"title\": title,\n",
    "            \"content\": content\n",
    "        }\n",
    "        headers = {'Content-Type': 'application/json; charset=utf-8'}\n",
    "        res = requests.post(D_ENGINE_URL, headers=headers, json=payload, verify=False)\n",
    "        return res.json()\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "def send_to_engine_embedding(title, content):\n",
    "    D_ENGINE_URL = \"url\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"title\": title,\n",
    "            \"content\": content\n",
    "        }\n",
    "        headers = {'Content-Type': 'application/json; charset=utf-8'}\n",
    "        res = requests.post(D_ENGINE_URL, headers=headers, json=payload, verify=False)\n",
    "        return res.json()\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "def jaccard_similarity(s1, s2):\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    return len(s1 & s2) / len(s1 | s2)\n",
    "# Elasticsearch 연결 생성\n",
    "es = Elasticsearch([{'host': host, 'port': port, 'scheme': scheme}])\n",
    "\n",
    "# Elasticsearch에서 데이터 가져오기\n",
    "query = {\"query\": {\"match_all\": {}}}\n",
    "result = es.search(index='index', size=10000)\n",
    "hits_total = result['hits']['hits']\n",
    "\n",
    "# Elasticsearch에서 가져온 데이터를 리스트에 저장\n",
    "document_vectors = []\n",
    "document_keywords = []\n",
    "total_rank_list=[]\n",
    "for hit in hits_total:\n",
    "    source = hit['_source']\n",
    "    vector = source.get('vector', '')\n",
    "    keyword = source.get('keyword', '')\n",
    "    url = source.get('url', '')\n",
    "    document_vectors.append({\"vector\" : vector, \"url\" : url})\n",
    "    document_keywords.append({\"keyword\" : keyword, \"url\" : url})\n",
    "\n",
    "# 결과 출력\n",
    "for i, idx in enumerate(ranked_indices):\n",
    "    # print(f\"Rank {i + 1}:\")\n",
    "    # print(f\"  URL: {url_data[idx]['URL']}\")\n",
    "    # print(f\"  Clicks: {clicks[idx]}\")\n",
    "    # print(f\"  Dwell Time: {dwell_times[idx]} ms\")\n",
    "    # print(f\"  Score: {weighted_scores[idx]}\\n\")\n",
    "\n",
    "    # Elasticsearch에서 데이터 가져오기\n",
    "    selected_url = url_data[idx]['URL']\n",
    "    query = {\n",
    "        \"aggs\": {},\n",
    "        \"size\": 1,\n",
    "        \"script_fields\": {},\n",
    "        \"stored_fields\": [\"_source\"],\n",
    "        \"runtime_mappings\": {},\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"match_phrase\": {\n",
    "                            \"url\": selected_url\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"should\": [],\n",
    "                \"must_not\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result = es.search(index='index-policy-2023', body=query)\n",
    "    hits = result['hits']['hits']\n",
    "    total_rank = []\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        url = source.get('url', '')\n",
    "        keyword = source.get('keyword', '')\n",
    "        title = source.get('title', '')\n",
    "        content = source.get('content', '')\n",
    "        vector = source.get('vector', '')\n",
    "\n",
    "        # 입력 데이터 설정\n",
    "        input_keyword_data = send_to_engine_keyword(title, content)\n",
    "        input_embedding_data = send_to_engine_embedding(title, content)\n",
    "        input_keyword_str = input_keyword_data['keywords']\n",
    "        input_embedding_str = input_embedding_data['embedding']\n",
    "        input_keywords = set(input_keyword_str)\n",
    "        input_vector = np.array(input_embedding_str)\n",
    "\n",
    "        # 자카드 유사도 계산\n",
    "        similarities_jac = []\n",
    "        for document_keyword in document_keywords:\n",
    "            keyword = document_keyword['keyword']  # 'keyword'가 없으면 None을 반환\n",
    "            if keyword is not None:\n",
    "                similarity_jac = jaccard_similarity(input_keywords, keyword)\n",
    "                similarities_jac.append((document_keyword['url'], similarity_jac))  # 'url'과 유사도를 튜플로 저장\n",
    "            \n",
    "        # 코사인 유사도 계산\n",
    "        document_vectors_np = np.array([document_vector['vector'] for document_vector in document_vectors])\n",
    "        similarities_cos = cosine_similarity([input_vector], document_vectors_np)\n",
    "        most_similar_indices = np.argsort(similarities_cos[0])[::-1]  # 내림차순 정렬된 인덱스 배열\n",
    "        # 상위의 유사한 데이터 출력\n",
    "        top_5_results_cos = []\n",
    "        for index in most_similar_indices[:50]:\n",
    "            most_similar_source = hits_total[index]['_source']\n",
    "            most_similar_url = most_similar_source['url']\n",
    "            cosine_similarity_score = similarities_cos[0][index]\n",
    "            top_5_results_cos.append((most_similar_url, cosine_similarity_score))\n",
    "        # 자카드 유사도가 높은 순으로 결과 정렬\n",
    "        sorted_results_jac = sorted(similarities_jac, key=lambda x: x[1], reverse=True)\n",
    "        # 상위의 결과 선택\n",
    "        top_5_results_jac = sorted_results_jac[:50]\n",
    "        # top_5_results_cos와 top_5_results_jac에서 URL이 일치하는 값들의 점수 합산\n",
    "        # combined_scores 리스트에 jac + cos score + weighted_scores[idx]를 저장\n",
    "        combined_scores = []\n",
    "        for url_cos, score_cos in top_5_results_cos:\n",
    "            url_already_added = False  # URL이 이미 추가되었는지 확인하는 플래그\n",
    "            for url_jac, score_jac in top_5_results_jac:\n",
    "                if url_cos == url_jac:\n",
    "                    total_score = score_cos + score_jac + weighted_scores[idx]\n",
    "                    combined_scores.append((url_cos, total_score))\n",
    "                    url_already_added = True  # URL이 추가되었음을 표시\n",
    "                    break  # URL이 일치하면 반복문 종료\n",
    "            # URL이 이미 추가되지 않았다면 score_cos만 추가\n",
    "            if not url_already_added:\n",
    "                total_score = score_cos + weighted_scores[idx]\n",
    "                combined_scores.append((url_cos, total_score))\n",
    "        # 합산 점수를 기준으로 정렬\n",
    "        combined_scores = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "        # 결과 출력\n",
    "        for i, (url, total_score) in enumerate(combined_scores[:5]):\n",
    "            total_rank.append((url, total_score))\n",
    "        total_rank_list.append(total_rank)\n",
    "# total_rank_list를 점수(score)를 기준으로 정렬\n",
    "total_rank_list = sorted(total_rank_list, key=lambda x: x[0][1], reverse=True)\n",
    "\n",
    "# total_rank_list 내의 모든 URL과 점수를 하나의 리스트에 모음\n",
    "all_scores = []\n",
    "for ranked_items in total_rank_list:\n",
    "    all_scores.extend(ranked_items)\n",
    "\n",
    "# 스코어(score)를 기준으로 정렬\n",
    "sorted_scores = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "# 정렬된 스코어를 출력\n",
    "final_set = []\n",
    "for rank, (url, score) in enumerate(sorted_scores):\n",
    "    if url not in selected_url_list:\n",
    "        final_set.append((url, score))\n",
    "        \n",
    "for rank, (url, score) in enumerate(final_set[:5]):        \n",
    "    print(f\"Rank {rank + 1}:\")\n",
    "    print(f\"  URL: {url}\")\n",
    "    print(f\"  Score: {score}\")\n",
    "    print(\"-------------------------\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
